{
 "metadata": {
  "name": "",
  "signature": "sha256:a67a3c7d000ce0458a47ef569e35319fa43e19d9df2476b84d0a2d35c232fb37"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Job register web scrapper.\n",
      "## Michael Gully-Santiago, October 2, 2014\n",
      "\n",
      "Basically I'm scaping the Job Register website to compile all the job add into into a single Excel file.\n",
      "\n",
      "I am following [this example](http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/) from Greg Reda."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "from urllib2 import urlopen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import time\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BASE_URL = \"https://jobregister.aas.org/\"\n",
      "html = urlopen(BASE_URL).read()\n",
      "soup = BeautifulSoup(html, \"lxml\")\n",
      "pppcp2 = soup.find(\"div\", \"panel-pane pane-custom pane-2\")\n",
      "paneContent = pppcp2.find(\"div\", \"pane-content\")\n",
      "pcTab = paneContent.find(\"table\")\n",
      "allRows = pcTab.findAll(\"tr\")\n",
      "len(allRows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "222"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lordList = []\n",
      "dots = '.'\n",
      "for row in allRows:\n",
      "    td = row.find(\"td\")\n",
      "    if (td != None):\n",
      "        link = td.a[\"href\"]\n",
      "        lordList.append(BASE_URL+link)\n",
      "\n",
      "#lordList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## woohoo, it works!!\n",
      "\n",
      "The next step is to now go to each page and scrape the desired information.\n",
      "\n",
      "By the way, you'll notice that it's not sorted by the job category (postdocs, Faculty, etc).  This is OK because there is a \"Job Category\" listing that we can use to sort things out later.\n",
      "\n",
      "Let's just pick **one** link to do our operations on.  We can iterate on all the links after it works for **one**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thisLink = lordList[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print thisLink\n",
      "type(thisLink)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "https://jobregister.aas.org/job_view?JobID=48914\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "str"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start off by just collecting the:\n",
      "\n",
      "1. post date\n",
      "2. deadline date\n",
      "3. job type\n",
      "4. institution/company name\n",
      "\n",
      "The html tags for these are:\n",
      "+ `fieldset class=\"fieldgroup group-submission-dates\"`\n",
      "+ `fieldset class=\"fieldgroup group-job-details\"`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thisHtml = urlopen(thisLink).read()\n",
      "soup = BeautifulSoup(thisHtml, \"lxml\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Dates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gsd = soup.find(\"fieldset\", \"fieldgroup group-submission-dates\")\n",
      "dds = gsd.findAll(\"span\",\"date-display-single\")\n",
      "postDate = str(dds[0].contents[0])\n",
      "deadline = str(dds[2].contents[0])\n",
      "#assumes 3 dates are posted...\n",
      "print postDate\n",
      "print deadline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "October 1, 2014\n",
        "November 30, 2014\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Job details"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gjd = soup.find(\"fieldset\", \"fieldgroup group-job-details\")\n",
      "\n",
      "# Job Category:\n",
      "ftf_JC = gjd.find(\"div\",\"field field-type-text field-field-job-category\")\n",
      "jobCatLabel = ftf_JC.find(\"div\", \"field-label-inline-first\")\n",
      "# re.sub gets rid of multiple spaces\n",
      "jobCat = str(re.sub(' +',' ',jobCatLabel.next_sibling)).replace(\"\\r\\n\", \"\")\n",
      "\n",
      "\n",
      "# Institution/Company Name:\n",
      "ftf_IN = gjd.find(\"div\",\"field field-type-text field-field-institution-name\")\n",
      "instituteLabel = ftf_IN.find(\"div\", \"field-label-inline-first\")\n",
      "institute = str(re.sub(' +',' ',instituteLabel.next_sibling)).replace(\"\\r\\n\", \"\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (postDate, deadline, jobCat, institute)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('October 1, 2014', 'November 30, 2014', ' Faculty Positions (visiting and non-tenure) ', ' Johns Hopkins University ')\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Ok, it's all working.  \n",
      "\n",
      "Let's put it all together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Just deal with a subset at first\n",
      "subLordList = lordList[0:5]\n",
      "\n",
      "for webLink in subLordList:\n",
      "    print webLink\n",
      "    thing1 = 'abc'\n",
      "    thing2 = ' jhk '\n",
      "    out1 = (thing1, thing2)\n",
      "    print out1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "https://jobregister.aas.org/job_view?JobID=48914\n",
        "('abc', ' jhk ')\n",
        "https://jobregister.aas.org/job_view?JobID=49155\n",
        "('abc', ' jhk ')\n",
        "https://jobregister.aas.org/job_view?JobID=49157\n",
        "('abc', ' jhk ')\n",
        "https://jobregister.aas.org/job_view?JobID=49320\n",
        "('abc', ' jhk ')\n",
        "https://jobregister.aas.org/job_view?JobID=49327\n",
        "('abc', ' jhk ')\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}